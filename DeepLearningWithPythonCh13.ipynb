{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices for real World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the most out of your models\n",
    "\n",
    "Blindly trying out different architecture configurations works well enough if you just need something that works okay. In this section, we'll go beyond \"works okay\" to \"works great and wins ml competitions\" via a set of must-know techniques for building state-of-the-art deep learning models.\n",
    "\n",
    "### Hyperparams optimization\n",
    "\n",
    "When building a DL model, you have to make many seemingly arbitrary decisions. These architecture-level parameters are called hyperparameters to distinguish them from the parameters of a model, which are trained via backpropagation.\\\n",
    "\\\n",
    "In practice, experienced ML engineers and researchers build intuition over time as to what works and what does not when it comes to these choices- they develop hyperparameters-tuning skills. But there are no formal rules. If you want to get the very limit of what can be achieved, you can't be content with such arbitrary choices. Your initial decisions are almost always suboptimal, even if you have good intuition. You can refine your choices by tweaking them by hand and retraining the model repeatedly. But it shouldn't be your job as a human to fiddle with hyperparams all day.\\\n",
    "Thus you need to explore the space of possible decisions automatically, systematically, in principled way. You need to search the architecture space and find the best performing architectures empirically.\\\n",
    "The process of optimizing hyperparameters typically looks like this:\n",
    "1. Choose a set of hyperparams.\n",
    "2. Build the corresponding model.\n",
    "3. Fit it to your training data, and measure performance on the validation data.\n",
    "4. Choose the next set of hyperparams to try\n",
    "5. Repeat\n",
    "6. Eventually, measure performance on your test data.\n",
    "\n",
    "The key to this process is the algorithm that analyzes the relationship between validatio performance and various hyperparameter values to choose the next set of hyperparameters to evaluate. Many different techniques are possible: Bayesian optimization, generic algorithms, simple random search, and so on.\\\n",
    "Training the weights of a model is relatively easy: you compute a loss function on a mini-batch of data and then use backpropagation to move the weights in the right direction. Updating hyperparameters, on the other hand, presents unique challenges.\n",
    "Consider these points:\n",
    "* The hyperparam space is typically made up of discrete decisions and thus is not continuous or differentiable. Hence, you typically cannot do gradient descent in hyperparameters space. Instead, you must rely on gradient-free optimization techniques, which naturally are far less efficient than gradient descent.\n",
    "* Computing the feedback signal of this optimization process can be extremely expensive: it requires creating and training a new model from scratch on your dataset.\n",
    "* The feedback signal may be noisy: if a training run performs 0.2\\% better, is that because of better model configuration, or because you got lucky with the initial weight values?\n",
    "\n",
    "#### Using KerasTuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (d:\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\envs\\tf\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KerasTuner lets you replace hard-coded hyperparams values, such as units=32, with a range of possible choices, such as Int(name=\"units\",min_value=16,max_values=64, step=16). This set of choices in a given model is called the search space of the hyperparameter tuning process.\\\n",
    "To specify a search space, define a model-building function. It takes an hp argument, from which you can sample hyperparameter ranges, and it returns a compiled Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More modular and configurable approach to model-building, you can also subclass HyperModel class and define a build method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "class SimpleMLP(kt.HyperModel):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def build(self, hp):\n",
    "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(units, activation=\"relu\"),\n",
    "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
    "        ])\n",
    "        optimzer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "        model.compile(optimizer=optimzer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define a \"tuner\". Schematically, you can think of a tuner as a for loop that will:\n",
    "* Pick a set of hyperparams values\n",
    "* Call the model-building function with these values to create a model\n",
    "* Train the model and record its metrics\n",
    "\n",
    "KerasTuner has several built-in tuners available-RandomSearch, BayesianOptimization, and Hyperband. Let's try BayesianOptimization, a tuner that attempts to make smart predictions for which new hyperparameter values are likely to perform best given the outcomes of previous choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner=kt.BayesianOptimization(build_model,objective=\"val_accuracy\",max_trials=100,executions_per_trial=2, directory=\"mnist_kt_test\",overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 34s]\n",
      "val_accuracy: 0.934249997138977\n",
      "\n",
      "Best val_accuracy So Far: 0.9381999969482422\n",
      "Total elapsed time: 00h 48m 19s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train), (x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28*28)).astype(\"float32\")/255\n",
    "x_test = x_test.reshape((-1, 28*28)).astype(\"float32\")/255\n",
    "x_train_full = x_train[:]\n",
    "y_train_full = y_train[:]\n",
    "num_val_samples=10000\n",
    "x_train,x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]\n",
    "y_train,y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "]\n",
    "tuner.search(\n",
    "    x_train,y_train,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_val,y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Querying the best hyperparameter configurations\n",
    "top_n=4\n",
    "best_hps = tuner.get_best_hyperparameters(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can train on the full training data, there is one last parameter we need to settle: optimal number of epochs to train for. Typically, you will want to train the new models for longer than you did during the search: using aggressive patience value in the EarlyStopping callback saves time during search, but it may lead to underfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epoch(hp):\n",
    "    model = build_model(hp)\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", mode=\"min\", patience=10\n",
    "        )\n",
    "    ]\n",
    "    history = model.fit(x_train,y_train,\n",
    "                        validation_data=(x_val,y_val),\n",
    "                        epochs=100,\n",
    "                        batch_size=128,\n",
    "                        callbacks=callbacks)\n",
    "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
    "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    return best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.4623 - accuracy: 0.8735 - val_loss: 0.2419 - val_accuracy: 0.9312\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.2257 - accuracy: 0.9355 - val_loss: 0.1854 - val_accuracy: 0.9476\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.1768 - accuracy: 0.9500 - val_loss: 0.1579 - val_accuracy: 0.9576\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.1465 - accuracy: 0.9576 - val_loss: 0.1351 - val_accuracy: 0.9614\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.1244 - accuracy: 0.9650 - val_loss: 0.1295 - val_accuracy: 0.9641\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.1090 - accuracy: 0.9690 - val_loss: 0.1182 - val_accuracy: 0.9663\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 15s 38ms/step - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.1114 - val_accuracy: 0.9685\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.0860 - accuracy: 0.9760 - val_loss: 0.1073 - val_accuracy: 0.9684\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0767 - accuracy: 0.9785 - val_loss: 0.1037 - val_accuracy: 0.9705\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0690 - accuracy: 0.9798 - val_loss: 0.1022 - val_accuracy: 0.9708\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0624 - accuracy: 0.9821 - val_loss: 0.0979 - val_accuracy: 0.9713\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.0562 - accuracy: 0.9847 - val_loss: 0.0967 - val_accuracy: 0.9711\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0516 - accuracy: 0.9855 - val_loss: 0.0949 - val_accuracy: 0.9719\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 15s 39ms/step - loss: 0.0467 - accuracy: 0.9874 - val_loss: 0.0946 - val_accuracy: 0.9726\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0423 - accuracy: 0.9888 - val_loss: 0.0954 - val_accuracy: 0.9724\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0391 - accuracy: 0.9895 - val_loss: 0.0945 - val_accuracy: 0.9711\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0350 - accuracy: 0.9911 - val_loss: 0.0965 - val_accuracy: 0.9711\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0319 - accuracy: 0.9917 - val_loss: 0.0940 - val_accuracy: 0.9721\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0291 - accuracy: 0.9930 - val_loss: 0.0944 - val_accuracy: 0.9723\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0263 - accuracy: 0.9935 - val_loss: 0.0989 - val_accuracy: 0.9711\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.0984 - val_accuracy: 0.9714\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.0215 - accuracy: 0.9952 - val_loss: 0.1060 - val_accuracy: 0.9709\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0214 - accuracy: 0.9946 - val_loss: 0.0979 - val_accuracy: 0.9723\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 0.0983 - val_accuracy: 0.9730\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 15s 40ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.1028 - val_accuracy: 0.9709\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.1051 - val_accuracy: 0.9725\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.1033 - val_accuracy: 0.9728\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.1064 - val_accuracy: 0.9725\n",
      "Best epoch: 18\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m best_models \u001b[39m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m hp \u001b[39min\u001b[39;00m best_hps:\n\u001b[1;32m---> 12\u001b[0m     model \u001b[39m=\u001b[39m get_best_trained_model(hp)\n\u001b[0;32m     13\u001b[0m     model\u001b[39m.\u001b[39mevaluate(x_test, y_test)\n\u001b[0;32m     14\u001b[0m     best_models\u001b[39m.\u001b[39mappend(model)\n",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mget_best_trained_model\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_best_trained_model\u001b[39m(hp):\n\u001b[0;32m      2\u001b[0m     best_epoch \u001b[39m=\u001b[39m get_best_epoch(hp)\n\u001b[1;32m----> 3\u001b[0m     model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m      4\u001b[0m         x_train_full,y_train_full,\n\u001b[0;32m      5\u001b[0m         batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(best_epoch\u001b[39m*\u001b[39m\u001b[39m1.2\u001b[39m)\n\u001b[0;32m      6\u001b[0m     )\n\u001b[0;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def get_best_trained_model(hp):\n",
    "    best_epoch = get_best_epoch(hp)\n",
    "    model.fit(\n",
    "        x_train_full,y_train_full,\n",
    "        batch_size=128, epochs=int(best_epoch*1.2)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "best_models = []\n",
    "for hp in best_hps:\n",
    "    model = get_best_trained_model(hp)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    best_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'HyperParameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_models \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39;49mget_best_models(hp)\n",
      "File \u001b[1;32md:\\envs\\tf\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:366\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \n\u001b[0;32m    350\u001b[0m \u001b[39mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[39m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[1;32m--> 366\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mget_best_models(num_models)\n",
      "File \u001b[1;32md:\\envs\\tf\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:363\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_best_models\u001b[39m(\u001b[39mself\u001b[39m, num_models\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    349\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[39m    This method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[39m        List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     best_trials \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moracle\u001b[39m.\u001b[39;49mget_best_trials(num_models)\n\u001b[0;32m    364\u001b[0m     models \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_model(trial) \u001b[39mfor\u001b[39;00m trial \u001b[39min\u001b[39;00m best_trials]\n\u001b[0;32m    365\u001b[0m     \u001b[39mreturn\u001b[39;00m models\n",
      "File \u001b[1;32md:\\envs\\tf\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:514\u001b[0m, in \u001b[0;36mOracle.get_best_trials\u001b[1;34m(self, num_trials)\u001b[0m\n\u001b[0;32m    502\u001b[0m trials \u001b[39m=\u001b[39m [\n\u001b[0;32m    503\u001b[0m     t\n\u001b[0;32m    504\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mvalues()\n\u001b[0;32m    505\u001b[0m     \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    506\u001b[0m ]\n\u001b[0;32m    508\u001b[0m sorted_trials \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\n\u001b[0;32m    509\u001b[0m     trials,\n\u001b[0;32m    510\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m trial: trial\u001b[39m.\u001b[39mscore,\n\u001b[0;32m    511\u001b[0m     reverse\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mdirection \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    512\u001b[0m )\n\u001b[1;32m--> 514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(sorted_trials) \u001b[39m<\u001b[39;49m num_trials:\n\u001b[0;32m    515\u001b[0m     sorted_trials \u001b[39m=\u001b[39m sorted_trials \u001b[39m+\u001b[39m [\n\u001b[0;32m    516\u001b[0m         t\n\u001b[0;32m    517\u001b[0m         \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mvalues()\n\u001b[0;32m    518\u001b[0m         \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mstatus \u001b[39m!=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    519\u001b[0m     ]\n\u001b[0;32m    520\u001b[0m \u001b[39mreturn\u001b[39;00m sorted_trials[:num_trials]\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'HyperParameters'"
     ]
    }
   ],
   "source": [
    "best_models = tuner.get_best_models(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
