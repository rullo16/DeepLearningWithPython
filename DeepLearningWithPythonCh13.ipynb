{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices for real World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the most out of your models\n",
    "\n",
    "Blindly trying out different architecture configurations works well enough if you just need something that works okay. In this section, we'll go beyond \"works okay\" to \"works great and wins ml competitions\" via a set of must-know techniques for building state-of-the-art deep learning models.\n",
    "\n",
    "### Hyperparams optimization\n",
    "\n",
    "When building a DL model, you have to make many seemingly arbitrary decisions. These architecture-level parameters are called hyperparameters to distinguish them from the parameters of a model, which are trained via backpropagation.\\\n",
    "\\\n",
    "In practice, experienced ML engineers and researchers build intuition over time as to what works and what does not when it comes to these choices- they develop hyperparameters-tuning skills. But there are no formal rules. If you want to get the very limit of what can be achieved, you can't be content with such arbitrary choices. Your initial decisions are almost always suboptimal, even if you have good intuition. You can refine your choices by tweaking them by hand and retraining the model repeatedly. But it shouldn't be your job as a human to fiddle with hyperparams all day.\\\n",
    "Thus you need to explore the space of possible decisions automatically, systematically, in principled way. You need to search the architecture space and find the best performing architectures empirically.\\\n",
    "The process of optimizing hyperparameters typically looks like this:\n",
    "1. Choose a set of hyperparams.\n",
    "2. Build the corresponding model.\n",
    "3. Fit it to your training data, and measure performance on the validation data.\n",
    "4. Choose the next set of hyperparams to try\n",
    "5. Repeat\n",
    "6. Eventually, measure performance on your test data.\n",
    "\n",
    "The key to this process is the algorithm that analyzes the relationship between validatio performance and various hyperparameter values to choose the next set of hyperparameters to evaluate. Many different techniques are possible: Bayesian optimization, generic algorithms, simple random search, and so on.\\\n",
    "Training the weights of a model is relatively easy: you compute a loss function on a mini-batch of data and then use backpropagation to move the weights in the right direction. Updating hyperparameters, on the other hand, presents unique challenges.\n",
    "Consider these points:\n",
    "* The hyperparam space is typically made up of discrete decisions and thus is not continuous or differentiable. Hence, you typically cannot do gradient descent in hyperparameters space. Instead, you must rely on gradient-free optimization techniques, which naturally are far less efficient than gradient descent.\n",
    "* Computing the feedback signal of this optimization process can be extremely expensive: it requires creating and training a new model from scratch on your dataset.\n",
    "* The feedback signal may be noisy: if a training run performs 0.2\\% better, is that because of better model configuration, or because you got lucky with the initial weight values?\n",
    "\n",
    "#### Using KerasTuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KerasTuner lets you replace hard-coded hyperparams values, such as units=32, with a range of possible choices, such as Int(name=\"units\",min_value=16,max_values=64, step=16). This set of choices in a given model is called the search space of the hyperparameter tuning process.\\\n",
    "To specify a search space, define a model-building function. It takes an hp argument, from which you can sample hyperparameter ranges, and it returns a compiled Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:33:00.385201: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More modular and configurable approach to model-building, you can also subclass HyperModel class and define a build method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "class SimpleMLP(kt.HyperModel):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def build(self, hp):\n",
    "        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "        model = keras.Sequential([\n",
    "            layers.Dense(units, activation=\"relu\"),\n",
    "            layers.Dense(self.num_classes, activation=\"softmax\")\n",
    "        ])\n",
    "        optimzer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "        model.compile(optimizer=optimzer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define a \"tuner\". Schematically, you can think of a tuner as a for loop that will:\n",
    "* Pick a set of hyperparams values\n",
    "* Call the model-building function with these values to create a model\n",
    "* Train the model and record its metrics\n",
    "\n",
    "KerasTuner has several built-in tuners available-RandomSearch, BayesianOptimization, and Hyperband. Let's try BayesianOptimization, a tuner that attempts to make smart predictions for which new hyperparameter values are likely to perform best given the outcomes of previous choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:33:02.314172: I tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc:840] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:33:02.431599: I tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc:840] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:33:02.431667: I tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc:840] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:33:02.432579: I tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc:840] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:33:02.432652: I tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc:840] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:33:02.432690: I tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc:840] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:33:02.433268: I tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc:840] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:33:02.433394: I tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc:840] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:33:02.433433: I tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc:840] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:33:02.433453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15828 MB memory:  -> device: 0, name: AMD Radeon RX 6800 XT, pci bus id: 0000:0a:00.0\n",
      "2023-07-25 09:33:02.741981: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:33:02.933641: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:33:02.936206: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:33:02.939414: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:33:02.940097: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:33:02.940575: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:33:02.943374: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:33:02.944779: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    }
   ],
   "source": [
    "tuner=kt.BayesianOptimization(build_model,objective=\"val_accuracy\",max_trials=100,executions_per_trial=2, directory=\"mnist_kt_test\",overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.9319999814033508\n",
      "\n",
      "Best val_accuracy So Far: 0.9382999837398529\n",
      "Total elapsed time: 00h 05m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train), (x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 28*28)).astype(\"float32\")/255\n",
    "x_test = x_test.reshape((-1, 28*28)).astype(\"float32\")/255\n",
    "x_train_full = x_train[:]\n",
    "y_train_full = y_train[:]\n",
    "num_val_samples=10000\n",
    "x_train,x_val = x_train[:-num_val_samples], x_train[-num_val_samples:]\n",
    "y_train,y_val = y_train[:-num_val_samples], y_train[-num_val_samples:]\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "]\n",
    "tuner.search(\n",
    "    x_train,y_train,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_val,y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Querying the best hyperparameter configurations\n",
    "top_n=4\n",
    "best_hps = tuner.get_best_hyperparameters(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can train on the full training data, there is one last parameter we need to settle: optimal number of epochs to train for. Typically, you will want to train the new models for longer than you did during the search: using aggressive patience value in the EarlyStopping callback saves time during search, but it may lead to underfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epoch(hp):\n",
    "    model = build_model(hp)\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", mode=\"min\", patience=10\n",
    "        )\n",
    "    ]\n",
    "    history = model.fit(x_train,y_train,\n",
    "                        validation_data=(x_val,y_val),\n",
    "                        epochs=100,\n",
    "                        batch_size=128,\n",
    "                        callbacks=callbacks)\n",
    "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
    "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    return best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:39.127860: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:39.134924: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:39.142437: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:39.187955: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:39.193056: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:39.196563: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:39.198921: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52/391 [==>...........................] - ETA: 0s - loss: 1.2248 - accuracy: 0.6705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:39.382910: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.8735 - val_loss: 0.2430 - val_accuracy: 0.9319\n",
      "Epoch 2/100\n",
      "  1/391 [..............................] - ETA: 0s - loss: 0.1790 - accuracy: 0.9531"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:40.161187: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:40.166418: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:40.178051: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:40.182666: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:40.185726: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:40.188024: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:40.228846: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.2223 - accuracy: 0.9364 - val_loss: 0.1802 - val_accuracy: 0.9493\n",
      "Epoch 3/100\n",
      "  3/391 [..............................] - ETA: 15s - loss: 0.2792 - accuracy: 0.9427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:41.061634: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:41.066135: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:41.069735: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1691 - accuracy: 0.9507 - val_loss: 0.1494 - val_accuracy: 0.9601\n",
      "Epoch 4/100\n",
      " 28/391 [=>............................] - ETA: 0s - loss: 0.1444 - accuracy: 0.9570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:41.995163: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:41.999851: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:42.003359: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1370 - accuracy: 0.9608 - val_loss: 0.1297 - val_accuracy: 0.9644\n",
      "Epoch 5/100\n",
      " 30/391 [=>............................] - ETA: 0s - loss: 0.1203 - accuracy: 0.9654"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:42.917295: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:42.922334: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:42.926090: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1174 - accuracy: 0.9659 - val_loss: 0.1188 - val_accuracy: 0.9657\n",
      "Epoch 6/100\n",
      " 28/391 [=>............................] - ETA: 0s - loss: 0.1024 - accuracy: 0.9718"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:43.767312: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:43.771718: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:43.774846: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9711 - val_loss: 0.1084 - val_accuracy: 0.9686\n",
      "Epoch 7/100\n",
      " 28/391 [=>............................] - ETA: 0s - loss: 0.0862 - accuracy: 0.9738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:44.603526: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:44.608472: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:44.612192: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0881 - accuracy: 0.9745 - val_loss: 0.1022 - val_accuracy: 0.9699\n",
      "Epoch 8/100\n",
      " 27/391 [=>............................] - ETA: 0s - loss: 0.0682 - accuracy: 0.9812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:45.465331: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:45.469579: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:45.472955: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9783 - val_loss: 0.0989 - val_accuracy: 0.9707\n",
      "Epoch 9/100\n",
      " 27/391 [=>............................] - ETA: 0s - loss: 0.0652 - accuracy: 0.9821"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:46.327152: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:46.331395: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:46.335329: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9800 - val_loss: 0.0976 - val_accuracy: 0.9707\n",
      "Epoch 10/100\n",
      " 29/391 [=>............................] - ETA: 0s - loss: 0.0724 - accuracy: 0.9790"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:47.234437: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:47.238463: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:47.241961: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0621 - accuracy: 0.9820 - val_loss: 0.0922 - val_accuracy: 0.9736\n",
      "Epoch 11/100\n",
      " 29/391 [=>............................] - ETA: 0s - loss: 0.0479 - accuracy: 0.9873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:48.066217: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:48.070340: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:48.073804: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.9842 - val_loss: 0.0898 - val_accuracy: 0.9737\n",
      "Epoch 12/100\n",
      " 29/391 [=>............................] - ETA: 0s - loss: 0.0497 - accuracy: 0.9873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:48.918755: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:48.923263: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:48.926585: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0505 - accuracy: 0.9859 - val_loss: 0.0889 - val_accuracy: 0.9741\n",
      "Epoch 13/100\n",
      " 29/391 [=>............................] - ETA: 0s - loss: 0.0405 - accuracy: 0.9884"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:49.773970: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:49.777943: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:49.780301: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0452 - accuracy: 0.9875 - val_loss: 0.0875 - val_accuracy: 0.9739\n",
      "Epoch 14/100\n",
      " 27/391 [=>............................] - ETA: 0s - loss: 0.0377 - accuracy: 0.9913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:50.647200: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:50.653224: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:50.655960: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0415 - accuracy: 0.9885 - val_loss: 0.0887 - val_accuracy: 0.9742\n",
      "Epoch 15/100\n",
      " 27/391 [=>............................] - ETA: 0s - loss: 0.0327 - accuracy: 0.9919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:51.521829: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:51.525041: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:51.527450: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.9896 - val_loss: 0.0873 - val_accuracy: 0.9741\n",
      "Epoch 16/100\n",
      " 29/391 [=>............................] - ETA: 0s - loss: 0.0298 - accuracy: 0.9922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:52.367598: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:52.372211: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:52.375306: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.9913 - val_loss: 0.0877 - val_accuracy: 0.9750\n",
      "Epoch 17/100\n",
      " 27/391 [=>............................] - ETA: 0s - loss: 0.0246 - accuracy: 0.9939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:53.179605: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:53.184450: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:53.187766: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0302 - accuracy: 0.9925 - val_loss: 0.0924 - val_accuracy: 0.9743\n",
      "Epoch 18/100\n",
      " 29/391 [=>............................] - ETA: 0s - loss: 0.0235 - accuracy: 0.9954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:54.044316: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:54.047692: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:54.050093: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9934 - val_loss: 0.0888 - val_accuracy: 0.9739\n",
      "Epoch 19/100\n",
      " 28/391 [=>............................] - ETA: 0s - loss: 0.0194 - accuracy: 0.9964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:54.877552: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:54.882383: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:54.893267: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9940 - val_loss: 0.0914 - val_accuracy: 0.9747\n",
      "Epoch 20/100\n",
      " 27/391 [=>............................] - ETA: 0s - loss: 0.0278 - accuracy: 0.9928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:55.736642: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:55.741015: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:55.743961: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9946 - val_loss: 0.0949 - val_accuracy: 0.9734\n",
      "Epoch 21/100\n",
      " 29/391 [=>............................] - ETA: 0s - loss: 0.0158 - accuracy: 0.9965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:56.589463: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:56.592676: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:56.595079: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9953 - val_loss: 0.0894 - val_accuracy: 0.9763\n",
      "Epoch 22/100\n",
      " 28/391 [=>............................] - ETA: 0s - loss: 0.0158 - accuracy: 0.9972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:57.427586: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:57.431832: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:57.435471: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 0.0925 - val_accuracy: 0.9753\n",
      "Epoch 23/100\n",
      " 27/391 [=>............................] - ETA: 0s - loss: 0.0120 - accuracy: 0.9980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:58.273337: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:58.277375: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:58.280881: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.0955 - val_accuracy: 0.9748\n",
      "Epoch 24/100\n",
      " 29/391 [=>............................] - ETA: 0s - loss: 0.0115 - accuracy: 0.9987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:59.144152: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:59.148057: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:59.151524: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.0941 - val_accuracy: 0.9742\n",
      "Epoch 25/100\n",
      " 28/391 [=>............................] - ETA: 0s - loss: 0.0117 - accuracy: 0.9989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:38:59.984311: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:59.989769: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:38:59.994038: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 1s 2ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.1008 - val_accuracy: 0.9758\n",
      "Best epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:39:00.833553: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:39:00.838182: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n",
      "2023-07-25 09:39:00.841754: I tensorflow/core/common_runtime/gpu_fusion_pass.cc:508] ROCm Fusion is enabled.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m best_models \u001b[39m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m hp \u001b[39min\u001b[39;00m best_hps:\n\u001b[0;32m---> 12\u001b[0m     model \u001b[39m=\u001b[39m get_best_trained_model(hp)\n\u001b[1;32m     13\u001b[0m     model\u001b[39m.\u001b[39mevaluate(x_test, y_test)\n\u001b[1;32m     14\u001b[0m     best_models\u001b[39m.\u001b[39mappend(model)\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mget_best_trained_model\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_best_trained_model\u001b[39m(hp):\n\u001b[1;32m      2\u001b[0m     best_epoch \u001b[39m=\u001b[39m get_best_epoch(hp)\n\u001b[0;32m----> 3\u001b[0m     model\u001b[39m.\u001b[39mfit(\n\u001b[1;32m      4\u001b[0m         x_train_full,y_train_full,\n\u001b[1;32m      5\u001b[0m         batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(best_epoch\u001b[39m*\u001b[39m\u001b[39m1.2\u001b[39m)\n\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def get_best_trained_model(hp):\n",
    "    best_epoch = get_best_epoch(hp)\n",
    "    model.fit(\n",
    "        x_train_full,y_train_full,\n",
    "        batch_size=128, epochs=int(best_epoch*1.2)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "best_models = []\n",
    "for hp in best_hps:\n",
    "    model = get_best_trained_model(hp)\n",
    "    model.evaluate(x_test, y_test)\n",
    "    best_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'int' and 'HyperParameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_models \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39;49mget_best_models(hp)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras_tuner/engine/tuner.py:366\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[1;32m    350\u001b[0m \u001b[39mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mget_best_models(num_models)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py:363\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[0;34m(self, num_models)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_best_models\u001b[39m(\u001b[39mself\u001b[39m, num_models\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    349\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[39m    This method is for querying the models trained during the search.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39m        List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     best_trials \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moracle\u001b[39m.\u001b[39;49mget_best_trials(num_models)\n\u001b[1;32m    364\u001b[0m     models \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_model(trial) \u001b[39mfor\u001b[39;00m trial \u001b[39min\u001b[39;00m best_trials]\n\u001b[1;32m    365\u001b[0m     \u001b[39mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras_tuner/engine/oracle.py:514\u001b[0m, in \u001b[0;36mOracle.get_best_trials\u001b[0;34m(self, num_trials)\u001b[0m\n\u001b[1;32m    502\u001b[0m trials \u001b[39m=\u001b[39m [\n\u001b[1;32m    503\u001b[0m     t\n\u001b[1;32m    504\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    505\u001b[0m     \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    506\u001b[0m ]\n\u001b[1;32m    508\u001b[0m sorted_trials \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\n\u001b[1;32m    509\u001b[0m     trials,\n\u001b[1;32m    510\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m trial: trial\u001b[39m.\u001b[39mscore,\n\u001b[1;32m    511\u001b[0m     reverse\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mdirection \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    512\u001b[0m )\n\u001b[0;32m--> 514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(sorted_trials) \u001b[39m<\u001b[39;49m num_trials:\n\u001b[1;32m    515\u001b[0m     sorted_trials \u001b[39m=\u001b[39m sorted_trials \u001b[39m+\u001b[39m [\n\u001b[1;32m    516\u001b[0m         t\n\u001b[1;32m    517\u001b[0m         \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    518\u001b[0m         \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mstatus \u001b[39m!=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    519\u001b[0m     ]\n\u001b[1;32m    520\u001b[0m \u001b[39mreturn\u001b[39;00m sorted_trials[:num_trials]\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'HyperParameters'"
     ]
    }
   ],
   "source": [
    "best_models = tuner.get_best_models(hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensembling\n",
    "\n",
    "Another powerful technique for obtaining the best possible results on a task is model ensembling. Ensembling consists of pooling together the predictions of a set of different models to produce better predictions. If you look at ML competitions you will see that the winners use very large ensembles of models that beat any single model.\\\n",
    "Ensembling relies on the assumption that different well-performing models trained indepenently are likely to be good for different reasons: each model looks at slightly different aspects of the data to make its predictions, getting part of the \"truth\" but not all of it.\\\n",
    "Let's use classification as an example. The easiest way to pool the predictions of a set of classifiers is to average their predictions at inference time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_a = model_a.predict(x_val)\n",
    "# preds_b = model_b.predict(x_val)\n",
    "# preds_c = model_c.predict(x_val)\n",
    "# preds_d = model_d.predict(x_val)\n",
    "# final_preds = 0.25 * (preds_a + preds_b + preds_c + preds_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However this will work only if the classifiers are more or less equally good. A smarter way is to do a weighted average, where the weights are learned on the validation data-typically, the better classifiers are given a higher weight, adn the worse are given a lower weight. To search for a good set of ensembling weights, you can use random search or a simple optimization algorithm, such as Nelder-Mead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_a = model_a.predict(x_val)\n",
    "# preds_b = model_b.predict(x_val)\n",
    "# preds_c = model_c.predict(x_val)\n",
    "# preds_d = model_d.predict(x_val)\n",
    "# final_preds = 0.5 * preds_a + 0.25*preds_b + 0.1*preds_c + 0.15*preds_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many variants you can do an average of an exponential of the predictions. In general, a simple weighted average with weights optimized on the validation data provides a very strong baseline.\\\n",
    "The key to making ensembling work is the diversity of the set of classifiers. Diversity is strength, it's what makes ensembling work. In ML terms, if all of your models are biased in the same way, your ensemble will retain this same bias. If your models are biased in different ways, the biases will cancel each other out, and the ensemble will be more robust and more accurate.\\\n",
    "For this reason, you should ensemble models that are as good as possible while being as different as possible. This typically means using very different architectures or even different brands of ML approaches. One thisng largely not worth doing is ensembling the same network trained several times independently, from different random initializations. If the only differente vetween your models is their random initialization and the order in which they were exposed to the training data, then your ensemble will be low-diversity and will provide only a tiny improvement over any single model.\\\n",
    "It's not so much how good your best model is; it's about the diversity of your set of candidate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling-up model training\n",
    "\n",
    "Recall \"loop of progress\" concept, the quality of your ideas is a function of how many refinement cucles they've been through. As the speed at which you can iterate on an idea is a function of how fast you can set up an experiment, how fast you can run that experiment, and finally, how well yuo can analyze the results.\\\n",
    "As you develop your expertise with the Keras API, how fast you can code up your deep\n",
    "learning experiments will cease to be the bottleneck of this progress cycle. The next\n",
    "bottleneck will become the speed at which you can train your models. Fast training\n",
    "infrastructure means that you can get your results back in 10–15 minutes, and hence,\n",
    "that you can go through dozens of iterations every day. Faster training directly improves\n",
    "the quality of your deep learning solutions.\\\n",
    "In this section, we see three ways to train model faster:\n",
    "* Mixed-precision training, which you can use even with a single GPU\n",
    "* Training on multiple GPUs\n",
    "* Training on multiple TPUs\n",
    "\n",
    "# Continues on the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
